#!/usr/bin/env python3
# -*- python -*-

# Copyright 2015 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

import sys
import argparse
import collections
import re
import numpy.random

NS = 1e-9
ptrSize = 8

class N(collections.namedtuple('N', 'mu sigma')):
    def val(self, state=numpy.random):
        return state.normal(self.mu, self.sigma)

    def __str__(self):
        return '%g±%g%%' % (self.mu, 100*self.sigma/self.mu)

    @classmethod
    def parser(cls, defaultPct):
        def parse(s):
            m = re.match(r'([-0-9.e]+)(?:(?:±|\+-?|-)([0-9.e]+)(%?))?', s)
            if not m:
                raise argparse.ArgumentTypeError('expected <float>[+-<float>[%]]')
            mu = float(m.group(1))
            if m.group(2) is not None:
                sigma = float(m.group(2))
                if m.group(3):
                    sigma = mu * (sigma / 100)
            else:
                sigma = mu * defaultPct
            return cls(mu, sigma)
        return parse

argp = argparse.ArgumentParser(
    epilog='''DIST arguments take a normal distribution in the form
    <float>[+-<float>[%]] where the first number gives the mean and
    the second gives the standard deviation, optionally as a
    percentage of the mean.  If the second is omitted, it uses the
    same percentage standard deviation as the default value.''')
argp.add_argument('--GOGC', metavar='PCT', type=float, default=100,
                  help='GOGC setting (default %(default)s)')
argp.add_argument('--pointerScanNS', metavar='NS', type=float, default=2,
                  help='Nanoseconds to scan a pointer (default %(default)s)')
argp.add_argument('--allocPeriodNS', metavar='DIST',
                  type=N.parser(0.2), default=N(100, 100 * 0.2),
                  help='Nanoseconds between allocations (default %(default)s)')
argp.add_argument('--w_true', metavar='DIST',
                  type=N.parser(0.01), default=N(0.1/ptrSize, 0.1/ptrSize*0.01),
                  help='True work ratio (default %(default)s)')
argp.add_argument('--u_mut', metavar='UTIL', type=float, default=1,
                  help='Mutator CPU utilization assuming no GC (default %(default)s)')
argp.add_argument('--seed', type=int, default=1,
                  help='Random seed')
args = argp.parse_args()
numpy.random.seed(args.seed)

#
# Simulation controls and state
#

# Constants
h_g = args.GOGC / 100
u_g = 0.25
K_T = 0.5
K_w = 0.75
u_mut = args.u_mut
gomaxprocs = 4
schedQuantum = 1/100          # Scheduler quantum in seconds

# GC state variables carried between cycles
w = w_initial = 0.1 * 1/ptrSize
h_T = 7/8

# System state
# The actual heap size doesn't matter much, as long as it's much
# larger than the typical allocation.
H_m_prev = H_m_initial = 16*1024*1024

# Simulation variables
pointerScanSecs = args.pointerScanNS * NS

def reachableBytes():
    """How many bytes of heap are reachable."""
    # Vary around initial size
    return max(0, int(H_m_initial * reachableBytes.state.normal(1, 0.1)))
    # Random walk
    #return max(0, int(H_m_prev * numpy.random.normal(1, 0.1)))
# Generate the same H_m sequence regardless of other things
reachableBytes.state = numpy.random.RandomState(numpy.random.randint(10000))

def workRatio():
    """Pointer/reachable byte ratio."""
    return max(0.001, args.w_true.val())

def allocBytes():
    """Bytes per allocation."""
    # TODO: This is a completely made up
    return int(numpy.random.lognormal(5, 0.5))

def allocPeriodSecs():
    """Seconds between allocations."""
    return max(0, args.allocPeriodNS.val() * NS)

#
# Simulator
#

class CycleSim:
    def __init__(self):
        # How much of the heap is reachable this cycle?
        # TODO: This and W_a should grow as the cycle progresses
        self.H_m = reachableBytes()

        # How much scan work do we need to do to scan all reachable pointers?
        self.W_a = self.H_m * workRatio()

        # Initial state
        self.W_done = 0
        self.H_a = H_T
        self.bgCredit = 0

        # Times are all CPU time (gomaxprocs CPU seconds per wall second)
        self.now = 0
        self.gcTime = self.gcTime_assist = self.gcTime_bg = self.gcTime_idle = 0

        self.allp = [PSim(self, i) for i in range(gomaxprocs)]

    def simulate(self):
        # Move time forward, allocating and scanning until we've done
        # W_a scan work. The 0.99.. is a fudge so we don't go into an
        # infinite loop at the end because of rounding errors.
        while self.W_done < self.W_a * 0.99999999:
            workRate, t = 0, float('inf')
            for p in self.allp:
                workRate1, t1 = p.next()
                workRate += workRate1
                t = min(t, t1)
            # If the work rate will put us over the actual work during
            # this step, back off the step time.
            if self.W_done + t * workRate > self.W_a:
                t = (self.W_a - self.W_done) / workRate
            # Step time forward by t for all Ps.
            for p in self.allp:
                p.simulate(t)
            self.now += t * gomaxprocs
            # gcTime does *not* include idle scanning.
            self.gcTime = self.gcTime_assist + self.gcTime_bg
            # Now that all Ps are at the same time, perform state
            # transitions.
            for p in self.allp:
                p.transition()

        # Report results
        u_assist = self.gcTime_assist / self.now
        u_bg = self.gcTime_bg / self.now
        u_idle = self.gcTime_idle / self.now
        return self.H_a, u_assist, u_bg, u_idle, self.W_a, self.H_m

class PSim:
    # Simulate one P. We treat each P as having one mutator G and one
    # GC G. It gets interrupted every schedQuantum seconds.

    def __init__(self, cycleSim, i):
        self.cycleSim = cycleSim
        self.i = i

        # running:   in user code for next runTime seconds, preemptible
        # assisting: in mutator assist for assistTime seconds, non-preemptible
        # bggc:      in background GC until preempt
        # idlegc:    in idle GC until preempt
        self.state = 'bggc'

        self.preemptTime = numpy.random.random() * schedQuantum
        self.preemptTime = 0
        self.runTime = allocPeriodSecs()
        self.assistTime = None

    def next(self):
        # Return the current work rate and the time of the next event on this P.
        if self.state == 'running':
            return 0, max(0, min(self.preemptTime, self.runTime))
        if self.state == 'assisting':
            return 1/pointerScanSecs, max(0, self.assistTime)
        if self.state == 'bggc' or self.state == 'idlegc':
            return 1/pointerScanSecs, max(0, self.preemptTime)

    def simulate(self, t):
        # Simulate this P for t seconds. There will be no state
        # changes during this time. This must not depend on anything
        # that other Ps are doing because time is stepped forward one
        # P at a time and hence may not be in sync.
        cs = self.cycleSim

        if self.state == 'running':
            assert self.runTime >= t
            self.runTime -= t
        elif self.state == 'assisting':
            # Perform assist work for t seconds
            W_assist = t / pointerScanSecs
            cs.W_done += W_assist
            cs.gcTime_assist += t

            assert self.assistTime >= t
            self.assistTime -= t
        elif self.state == 'bggc':
            W_bg = t / pointerScanSecs
            cs.W_done += W_bg
            cs.bgCredit += W_bg
            # TODO: The real code only flushes this at preemption,
            # which is lower fidelity.
            cs.gcTime_bg += t
        elif self.state == 'idlegc':
            W_idle = t / pointerScanSecs
            cs.W_done += W_idle
            cs.bgCredit += W_idle
            cs.gcTime_idle += t
        else:
            raise AssertionError('bad state %r' % self.state)

        self.preemptTime -= t   # May go negative during assisting

    def transition(self):
        # Perform any instantaneous state changes. All Ps are at the
        # same time.
        cs = self.cycleSim

        if self.state == 'running' and self.runTime == 0:
            # Do allocation (assume this is instantaneous).
            alloc = allocBytes()
            cs.H_a += alloc

            # Compute assist work for this allocation
            A = W_e/(H_g - H_T) * alloc
            # Steal assist work if we can
            steal = min(A, cs.bgCredit)
            cs.bgCredit -= steal
            A -= steal
            # Compute the time it will take to do A assist work
            self.assistTime = A * pointerScanSecs
            # Switch to assisting
            self.state = 'assisting'

        if self.state == 'assisting' and self.assistTime == 0:
            # Switch back to running
            self.state = 'running'
            self.runTime = allocPeriodSecs()

        preemptible = self.state in ('running', 'bggc', 'idlegc')
        if preemptible and self.preemptTime <= 0:
            self.preemptTime = schedQuantum

            # If this P and all lower-numbered Ps were to run
            # background GC for the next quantum, would u_a <= u_g at
            # the end of the quantum?
            u_a_if_bg = (cs.gcTime + (self.i + 1) * schedQuantum) / (cs.now + gomaxprocs * schedQuantum)
            if u_a_if_bg <= u_g:
                # Run background GC for the next quantum
                self.state = 'bggc'
                return

            # Does the mutator want to run?
            if numpy.random.random() <= u_mut:
                self.state = 'running'
                return

            # Otherwise, run idle GC next quantum
            self.state = 'idlegc'

print("# h_g=%g w_true=%g pointerScanTime=%gns allocPeriod=%gns u_mut=%g" % (h_g, args.w_true.mu, pointerScanSecs/NS, args.allocPeriodNS.mu, u_mut))
print("n\tH_m(n-1)\tH_t\tH_a\tH_g\tW_a\tW_e\tw\tu_a\tu_g\tu_assist\tu_bg\tu_idle")
for n in range(20):
    H_T = H_m_prev * (1 + h_T)
    H_g = H_m_prev * (1 + h_g)
    #W_e = w * H_g           # Old w definition
    W_e = w * H_m_prev            # New w definition

    # Simulate a concurrent cycle
    H_a, u_assist, u_bg, u_idle, W_a, H_m = CycleSim().simulate()
    u_a = u_assist + u_bg

    print(n, H_m_prev, H_T, H_a, H_g, W_a*ptrSize, W_e*ptrSize, w, u_a, u_g, u_assist, u_bg, u_idle, sep='\t')
    sys.stdout.flush()

    # Update heap trigger
    h_a = H_a / H_m_prev - 1
    e = h_g - h_T - u_a/u_g*(h_a - h_T)
    h_T = max(0, h_T + K_T * e)

    # Update work estimate
    #w = K_w*W_a/H_a + (1 - K_w)*w # Old w definition
    w = K_w*W_a/H_m + (1 - K_w)*w # New w definition

    # Update H_m_prev
    H_m_prev = H_m
print()
print()
