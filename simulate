#!/usr/bin/env python3
# -*- python -*-

# Copyright 2015 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

import sys
import argparse
import collections
import re
import numpy.random

NS = 1e-9
ptrSize = 8

class N(collections.namedtuple('N', 'mu sigma')):
    def val(self, state=numpy.random):
        return state.normal(self.mu, self.sigma)

    def __str__(self):
        return '%g±%g%%' % (self.mu, 100*self.sigma/self.mu)

    @classmethod
    def parser(cls, defaultPct):
        def parse(s):
            m = re.match(r'([-0-9.e]+)(?:(?:±|\+-?|-)([0-9.e]+)(%?))?', s)
            if not m:
                raise argparse.ArgumentTypeError('expected <float>[+-<float>[%]]')
            mu = float(m.group(1))
            if m.group(2) is not None:
                sigma = float(m.group(2))
                if m.group(3):
                    sigma = mu * (sigma / 100)
            else:
                sigma = mu * defaultPct
            return cls(mu, sigma)
        return parse

argp = argparse.ArgumentParser(
    epilog='''DIST arguments take a normal distribution in the form
    <float>[+-<float>[%]] where the first number gives the mean and
    the second gives the standard deviation, optionally as a
    percentage of the mean.  If the second is omitted, it uses the
    same percentage standard deviation as the default value.''')
argp.add_argument('--GOGC', metavar='PCT', type=float, default=100,
                  help='GOGC setting (default %(default)s)')
argp.add_argument('--pointerScanNS', metavar='NS', type=float, default=2,
                  help='Nanoseconds to scan a pointer (default %(default)s)')
argp.add_argument('--allocPeriodNS', metavar='DIST',
                  type=N.parser(0.2), default=N(100, 100 * 0.2),
                  help='Nanoseconds between allocations (default %(default)s)')
argp.add_argument('--w_true', metavar='DIST',
                  type=N.parser(0.01), default=N(0.1/ptrSize, 0.1/ptrSize*0.01),
                  help='True work ratio (default %(default)s)')
argp.add_argument('--u_mut', metavar='UTIL', type=float, default=1,
                  help='Mutator CPU utilization assuming no GC (default %(default)s)')
argp.add_argument('--seed', type=int, default=1,
                  help='Random seed')
args = argp.parse_args()
numpy.random.seed(args.seed)

#
# Simulation controls and state
#

# Constants
h_g = args.GOGC / 100
u_g = 0.25
K_T = 0.5
K_w = 0.75
u_mut = args.u_mut
gomaxprocs = 4
schedQuantum = 1/10000          # Scheduler quantum in seconds

# GC state variables carried between cycles
w = w_initial = 0.1 * 1/ptrSize
h_T = 7/8

# System state
# The actual heap size doesn't matter much, as long as it's much
# larger than the typical allocation.
H_m_prev = H_m_initial = 16*1024*1024

# Simulation variables
pointerScanSecs = args.pointerScanNS * NS

def reachableBytes():
    """How many bytes of heap are reachable."""
    # Vary around initial size
    return max(0, int(H_m_initial * reachableBytes.state.normal(1, 0.1)))
    # Random walk
    #return max(0, int(H_m_prev * numpy.random.normal(1, 0.1)))
# Generate the same H_m sequence regardless of other things
reachableBytes.state = numpy.random.RandomState(numpy.random.randint(10000))

def workRatio():
    """Pointer/reachable byte ratio."""
    return max(0.001, args.w_true.val())

def allocBytes():
    """Bytes per allocation."""
    # TODO: This is a completely made up
    return int(numpy.random.lognormal(5, 0.5))

def allocPeriodSecs():
    """Seconds between allocations."""
    return max(0, args.allocPeriodNS.val() * NS)

#
# Simulator
#

class CycleSim:
    def __init__(self):
        # How much of the heap is reachable this cycle?
        self.H_m = reachableBytes()

        # How much scan work do we need to do to scan all reachable pointers?
        self.W_a = self.H_m * workRatio()

        # Initial state
        self.W_done = 0
        self.H_a = H_T
        self.bgCredit = 0

        # Times are all CPU time (gomaxprocs CPU seconds per wall second)
        self.now = 0
        self.gcTime = self.gcTime_assist = self.gcTime_bg = self.gcTime_idle = 0

        self.allp = [PSim(self, i) for i in range(gomaxprocs)]

    def done(self):
        return self.W_done >= self.W_a

    def simulate(self):
        # Run schedule quanta, allocating and scanning until we've
        # done W_a scan work.
        quanta = 0
        while not self.done():
            # gcTime does *not* include idle scanning
            self.gcTime = self.gcTime_assist + self.gcTime_bg
            for p in self.allp:
                p.simulate()
            self.now += gomaxprocs * schedQuantum
            quanta += 1
        if quanta < 3:
            # Since we don't simulate interleaving within a quantum,
            # results are inaccurate if we didn't run enough quanta.
            #
            # TODO: Use discrete event simulation to interleave within
            # a quantum, but still make scheduling decisions on
            # quantum boundaries.
            print('warning: cycle completed in %d quanta;'
                  ' decrease schedQuantum or increase H_m_initial' % quanta,
                  file=sys.stderr)

        # Report results
        u_assist = self.gcTime_assist / self.now
        u_bg = self.gcTime_bg / self.now
        u_idle = self.gcTime_idle / self.now
        return self.H_a, u_assist, u_bg, u_idle, self.W_a, self.H_m

class PSim:
    # Simulate one P. We treat each P as having one mutator G and one GC G.

    def __init__(self, cycleSim, i):
        self.cycleSim = cycleSim
        self.i = i

        self.allocDelay = allocPeriodSecs()
        self.assistTime = None
        self.state = 'running'

    def simulate(self):
        # Simulate this P for one schedQuantum
        cs = self.cycleSim

        # If this P and all lower-numbered Ps were to run background
        # GC, would u_a <= u_g at the end of the quantum?
        u_a_if_bg = (cs.gcTime + (self.i + 1) * schedQuantum) / (cs.now + gomaxprocs * schedQuantum)
        if u_a_if_bg <= u_g:
            # Run background GC this quantum
            W_bg = schedQuantum * pointerScanSecs
            cs.W_done += W_bg
            cs.bgCredit += W_bg
            cs.gcTime_bg += schedQuantum
            return

        # Is this mutator idle this quantum?
        if numpy.random.random() >= u_mut:
            # Run idle GC this quantum
            W_idle = schedQuantum * pointerScanSecs
            cs.W_done += W_idle
            cs.bgCredit += W_idle
            cs.gcTime_idle += schedQuantum
            return

        # Otherwise, run the mutator for a quantum
        left = schedQuantum
        while left > 0 and not cs.done():
            if self.state == 'running':
                step = min(left, self.allocDelay)
                self.allocDelay -= step
                left -= step

                if self.allocDelay <= 0:
                    # Do allocation (assume this is instantaneous).
                    alloc = allocBytes()
                    cs.H_a += alloc

                    # Compute assist work for this allocation
                    A = W_e/(H_g - H_T) * alloc
                    # Steal assist work if we can
                    steal = min(A, cs.bgCredit)
                    cs.bgCredit -= steal
                    A -= steal
                    # Compute the time it will take to do A assist work
                    self.assistTime = A * pointerScanSecs
                    # Switch to assisting
                    self.state = 'assisting'
            elif self.state == 'assisting':
                step = min(left, self.assistTime)
                self.assistTime -= step
                left -= step

                # Perform assist work for step seconds
                cs.W_done += step / pointerScanSecs
                cs.gcTime_assist += step

                if self.assistTime <= 0:
                    # Switch back to running and set up for the next
                    # allocation.
                    self.state = 'running'
                    self.allocDelay = allocPeriodSecs()

print("# h_g=%g w_true=%g pointerScanTime=%gns allocPeriod=%gns u_mut=%g" % (h_g, args.w_true.mu, pointerScanSecs/NS, args.allocPeriodNS.mu, u_mut))
print("n\tH_m(n-1)\tH_t\tH_a\tH_g\tW_a\tW_e\tw\tu_a\tu_g\tu_assist\tu_bg\tu_idle")
for n in range(20):
    H_T = H_m_prev * (1 + h_T)
    H_g = H_m_prev * (1 + h_g)
    #W_e = w * H_g           # Old w definition
    W_e = w * H_m_prev            # New w definition

    # Simulate a concurrent cycle
    H_a, u_assist, u_bg, u_idle, W_a, H_m = CycleSim().simulate()
    u_a = u_assist + u_bg

    print(n, H_m_prev, H_T, H_a, H_g, W_a*ptrSize, W_e*ptrSize, w, u_a, u_g, u_assist, u_bg, u_idle, sep='\t')
    sys.stdout.flush()

    # Update heap trigger
    h_a = H_a / H_m_prev - 1
    e = h_g - h_T - u_a/u_g*(h_a - h_T)
    h_T = max(0, h_T + K_T * e)

    # Update work estimate
    #w = K_w*W_a/H_a + (1 - K_w)*w # Old w definition
    w = K_w*W_a/H_m + (1 - K_w)*w # New w definition

    # Update H_m_prev
    H_m_prev = H_m
